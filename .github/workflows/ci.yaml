name: Continuous Test

on:
  push:
    branches:
      - 'main'
  pull_request: {}

jobs:
  lint:
    environment: continuous_test
    strategy:
      matrix:
        # Run for Python 3.8 only for now
        python-version: ['3.8']
        os: [ubuntu-latest]
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
      - name: Install dependencies
        run: |
          pip install isort flake8 interrogate
          echo "## CI/CD Summary :rocket:" >> $GITHUB_STEP_SUMMARY
          echo "-------------------------" >> $GITHUB_STEP_SUMMARY
      - name: Check imports with isort
        run: |
          # Show the diffs for debugging
          isort -c dasf_seismic_extras/
          if [[ $? -ne 0 ]] ; then
              echo "* **isort results:**" >> $GITHUB_STEP_SUMMARY
              echo "```diff" >> $GITHUB_STEP_SUMMARY
              isort -c --df dasf_seismic_extras/ >> $GITHUB_STEP_SUMMARY
              echo "```" >> $GITHUB_STEP_SUMMARY
              exit 1
          else
              echo "* **isort results:** :white_check_mark:" >> $GITHUB_STEP_SUMMARY
              exit 0
          fi
      - name: Lint with flake8
        run: |
          # stop the build if there are Python syntax errors or undefined names
          flake8 dasf_seismic_extras/ --count --select=E9,F63,F7,F82 --show-source --statistics
          # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          flake8 dasf_seismic_extras/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
          if [[ $? -ne 0 ]] ; then
              echo "* **flake8 results:**" >> $GITHUB_STEP_SUMMARY
              echo "```python" >> $GITHUB_STEP_SUMMARY
              flake8 dasf_seismic_extras/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics >> $GITHUB_STEP_SUMMARY
              echo "```" >> $GITHUB_STEP_SUMMARY
              exit 1
          else
              echo "* **flake8 results:** :white_check_mark:" >> $GITHUB_STEP_SUMMARY
              exit 0
          fi
#      - name: Doc lint with interrogate
#        run: |
#          echo "* **interrogate results:** $(interrogate -i --fail-under=15 dasf_seismic_extras/ | cut -d: -d" " -f4)" >> $GITHUB_STEP_SUMMARY
#          # We should have at least 80% of docs covered
#          interrogate -vv -i --fail-under=15 --badge-format svg -g /tmp/ -e build/ -e tests/ -e docs/

  test_cpu:
    runs-on: ubuntu-latest
    environment: continuous_test
    needs: [lint]
    container:
      image: docker.io/jcfaracco/dasf:cpu_ci
    steps:
      - uses: actions/checkout@v4
      - name: Install dependencies
        run: |
          pip install pytest-coverage pytest-benchmark paramiko parameterized mock --user --break-system-packages
      - name: Install project
        run: |
          pip install -e . --break-system-packages
      - name: Run test cases
        run: |
          pytest tests/

  test_gpu:
    runs-on: ubuntu-latest
    environment: continuous_test
    needs: [lint]
    # Skip this test for PRs due to dangerous code submitted.
    if: ${{ github.event_name != 'pull_request' }}
    steps:
      - name: Checkout ðŸ›Ž
        uses: actions/checkout@master
      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh/
          echo -e "${{ secrets.CLUSTER_SSH_CONFIG }}" > ~/.ssh/config
          echo -e "${{ secrets.CLUSTER_SSH_PRIV_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/*
          ssh-keyscan -H ${{ secrets.CLUSTER_ADDRESS }} >> ~/.ssh/known_hosts
      - name: Test SSH connection
        id: test_connection
        run: |
          ssh -o StrictHostKeyChecking=accept-new -T ${{ secrets.CLUSTER_GPU_ID }} exit > /dev/null
      - name: Pull latest docker image
        run: |
          ssh ${{ secrets.CLUSTER_GPU_ID }} "docker pull jcfaracco/dasf:gpu"
      - name: Clean up running containers
        run: |
          ssh ${{ secrets.CLUSTER_GPU_ID }} "docker stop dasf_seismic_extras_github || true && docker rm -f dasf_seismic_extras_github || true"
      - name: Update and commit the container
        run: |
          ssh ${{ secrets.CLUSTER_GPU_ID }} "nohup docker run --name dasf_seismic_extras_github --gpus all -v \$HOME:/data/:rw jcfaracco/dasf:gpu sh -c 'pip3 install pytest paramiko parameterized pytest-coverage pytest-benchmark pip --upgrade && rm -rf dasf-seismic-extras /data/dasf-seismic-extras/* && git clone https://github.com/discovery-unicamp/dasf-seismic-extras.git && cd dasf-seismic-extras/ && pip3 install -e . && mkdir -p /data/dasf-seismic-extras/ && cd -' && docker commit dasf_seismic_extras_github dasf_seismic_extras_github_live:latest && docker stop dasf_seismic_extras_github || true && docker rm -f dasf_seismic_extras_github || true"
      - name: Run test cases setup
        continue-on-error: true
        run: |
          ssh ${{ secrets.CLUSTER_GPU_ID }} "nohup docker run --name dasf_seismic_extras_github --gpus all -v \$HOME:/data/:rw dasf_seismic_extras_github_live:latest sh -c 'cd dasf-seismic-extras/ && pytest --cov dasf_seismic_extras/ --cov-report term --cov-report html:/data/dasf-seismic-extras/coverage_html --cov-report xml:/data/dasf-seismic-extras/coverage.xml --cov-report json:/data/dasf-seismic-extras/coverage.json tests/ && cd -'"
      - name: Clean up the last container
        run: |
          ssh ${{ secrets.CLUSTER_GPU_ID }} "docker stop dasf_seismic_extras_github || true && docker rm -f dasf_seismic_extras_github || true && docker rmi -f dasf_seismic_extras_github_live:latest || true"
      - name: Generate artifacts path
        run: mkdir -p deployment/gpu/tests/
      - name: Upload artifacts from runner
        run: |
          scp -r ${{ secrets.CLUSTER_GPU_ID }}:~/dasf-seismic-extras/* deployment/gpu/tests/
          # Convert HTML directory into a zip file and remove target
          zip -jrm deployment/gpu/tests/coverage-html.zip deployment/gpu/tests/coverage_html
      - name: Upload coverage HTML
        uses: actions/upload-artifact@v4
        with:
          name: coverage-html.zip
          path: deployment/gpu/tests/coverage-html.zip
          if-no-files-found: error
      - name: Coverage report
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: deployment/gpu/tests/coverage.xml
          badge: true
          fail_below_min: true
          format: markdown
          hide_branch_rate: false
          hide_complexity: true
          indicators: true
          output: both
          thresholds: '40 80'
      - name: Write to Job Summary
        run: cat code-coverage-results.md >> $GITHUB_STEP_SUMMARY
